{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c3208",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH = 'model1/1st.mp4'           # Path to your video file or rtsp link\n",
    "OUTPUT_DIR = 'output_frames'       # Directory to save annotated frames\n",
    "ANNOTATED_VIDEO = 'output_video.mp4'  # Output video \n",
    "FRAME_INTERVAL = 5                 \n",
    "\n",
    "# --- SETUP ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)  #model used\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_idx = 0\n",
    "json_results = []\n",
    "class_counter = Counter()\n",
    "frame_diversity = {}\n",
    "annotated_frames = []\n",
    "\n",
    "# --- PROCESS VIDEO ---\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_idx % FRAME_INTERVAL == 0:\n",
    "        # Run detection\n",
    "        results = model(frame)\n",
    "        detections = results.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2, conf, class]\n",
    "        frame_json = {\"frame_index\": frame_idx, \"detections\": []}\n",
    "        classes_in_frame = set()\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2, conf, cls = det\n",
    "            label = model.names[int(cls)]\n",
    "            bbox = [float(x1), float(y1), float(x2), float(y2)]\n",
    "            confidence = float(conf)\n",
    "            frame_json[\"detections\"].append({\n",
    "                \"class_label\": label,\n",
    "                \"bbox\": bbox,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "            class_counter[label] += 1\n",
    "            classes_in_frame.add(label)\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,0), 2)\n",
    "            cv2.putText(frame, f\"{label} {confidence:.2f}\", (int(x1), int(y1)-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "        frame_diversity[frame_idx] = len(classes_in_frame)\n",
    "        json_results.append(frame_json)\n",
    "        # Save annotated frame\n",
    "        annotated_path = os.path.join(OUTPUT_DIR, f\"frame_{frame_idx}.jpg\")\n",
    "        cv2.imwrite(annotated_path, frame)\n",
    "        annotated_frames.append(frame)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# --- SAVE JSON RESULTS ---\n",
    "with open('detection_results.json', 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "# --- OBJECT COUNTS PER CLASS ---\n",
    "print(\"\\nObject Counts Per Class:\")\n",
    "for cls, count in class_counter.items():\n",
    "    print(f\"{cls}: {count}\")\n",
    "\n",
    "# --- FRAME WITH MAXIMUM CLASS DIVERSITY (with error handling) ---\n",
    "if frame_diversity:\n",
    "    max_diversity_frame = max(frame_diversity, key=frame_diversity.get)\n",
    "    print(f\"\\nFrame with Maximum Class Diversity: {max_diversity_frame} \"\n",
    "          f\"({frame_diversity[max_diversity_frame]} unique classes)\")\n",
    "else:\n",
    "    print(\"\\nNo detections found in any frame. Cannot compute class diversity.\")\n",
    "\n",
    "# --- VISUALIZE OBJECT FREQUENCY ---\n",
    "if class_counter:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(class_counter.keys(), class_counter.values(), color='skyblue')\n",
    "    plt.xlabel('Object Class')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Object Frequency Across Video')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('object_frequency.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No objects detected, so no bar chart will be generated.\")\n",
    "\n",
    "# --- OPTIONAL: SAVE ANNOTATED VIDEO ---\n",
    "if annotated_frames:\n",
    "    height, width, _ = annotated_frames[0].shape\n",
    "    out = cv2.VideoWriter(ANNOTATED_VIDEO, cv2.VideoWriter_fourcc(*'mp4v'), 15, (width, height))\n",
    "    for frame in annotated_frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "    print(f\"Annotated video saved as {ANNOTATED_VIDEO}\")\n",
    "\n",
    "print(\"\\nDetection summary complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7f0ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
